{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NguyetDo_Project_W5_NLP_movie_reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2JQRJ4ae8br",
        "colab_type": "code",
        "outputId": "9c5171a6-73a4-4738-9ec6-407fe1d673f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5z3c7dBSOlb",
        "outputId": "85837297-0cb2-40c9-8183-db22e1ec84aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Import packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQu3hDu3fM9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data\n",
        "train = pd.read_csv('/drive/My Drive/FTMLE - Tonga/Data/movie_review.csv', encoding='utf-8', sep='\\t')\n",
        "test = pd.read_csv('/drive/My Drive/FTMLE - Tonga/Data/movie_review_evaluation.csv', encoding='utf-8', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZVkSbHdCds1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXCdAoX8Fzwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZjKOKBDfc0n",
        "colab_type": "code",
        "outputId": "8a11c6b2-9561-4381-b701-1ab6336914d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('The dimension of train data is {}.'.format(train.shape))\n",
        "print('The dimension of test data is {}.'.format(test.shape))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimension of train data is (22500, 3).\n",
            "The dimension of test data is (2500, 2).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXmRO-dp-ho5",
        "colab_type": "text"
      },
      "source": [
        "###Removing HTML Markup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIghM8zF-C7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['review_bs'] = train['review'].apply(lambda x: BeautifulSoup(x, 'html.parser'))\n",
        "# train.review_bs[0].get_text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT2A3m3U--en",
        "colab_type": "text"
      },
      "source": [
        "###Dealing with Punctuation, Numbers and Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eau7oSiF-cpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['review_letters_only'] = train['review_bs'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x.get_text()))\n",
        "# train['review_letters_only'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwV6Hhqc_Oq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['review_words'] = train['review_letters_only'].apply(lambda x: x.lower().split())\n",
        "# train['review_words'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnz-7lqO_cHH",
        "colab_type": "code",
        "outputId": "111c0c5c-f0ce-48f5-9d2e-8380ba5703fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set_of_stopwords = set(stopwords.words(\"english\"))\n",
        "train['review_meaningful_words'] = train['review_words'].apply(lambda x: [w for w in x if not w in set_of_stopwords])\n",
        "\n",
        "num_removed = len(train['review_words'][0]) - len(train['review_meaningful_words'][0])\n",
        "print('The number of stop words removed is {0}.'.format(num_removed))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the first review entry, the number of stop words removed is 218.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSexIOq-_qHw",
        "colab_type": "text"
      },
      "source": [
        "###Steming and Lemming (the accuracy afterward is higher without steming and lemming, therefore it will not be apply)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXAqLo43_jPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# porter_stemmer = PorterStemmer()\n",
        "# wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# train['review_stemmed'] = train['review_meaningful_words'].apply(\n",
        "#     lambda x: [porter_stemmer.stem(w) for w in x])\n",
        "# train['review_stemmed'] = train['review_cleaned'].apply(\n",
        "#     lambda x: [wordnet_lemmatizer.lemmatize(w) for w in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2RM2exQ_wlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train['review_cleaned'] = train['review_stemmed'].apply(lambda x: ' '.join(x)) # uncomment if using stemming\n",
        "train['review_cleaned'] = train['review_meaningful_words'].apply(lambda x: ' '.join(x)) # comment if using stemming"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyRRcC0x_8py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(['review', 'review_bs', 'review_letters_only', 'review_words', 'review_meaningful_words'], \n",
        "           axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKxQiH8AFxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3a645eee-1aeb-4759-c8f9-b5d0026a9a39"
      },
      "source": [
        "print(train['review_cleaned'][0])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryyO_qRqAU3o",
        "colab_type": "text"
      },
      "source": [
        "###Creating Features from a Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PhNbAeWAPTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer=\"word\", preprocessor=None, tokenizer=None, stop_words=None, max_features=5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxq0VQz0AjCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_features = vectorizer.fit_transform(list(train['review_cleaned'].values))\n",
        "train_data_features = train_data_features.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ7SlAgEAyZr",
        "colab_type": "code",
        "outputId": "da40bcce-6b75-45ae-ad77-1d6e691ff1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The dimension of train_data_features is {}.'.format(train_data_features.shape))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimension of train_data_features is (22500, 5000).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZnDxaSwAz9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcKnRbRhBCVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_reviews(reviews, remove_stopwords=False, stem=False):\n",
        "    \"\"\"\n",
        "    to clean review strings\n",
        "    review: a list of review strings\n",
        "    remove_stop_words: whether to remove stop words\n",
        "    output: a list of clean reviews\n",
        "    \"\"\"\n",
        "    # 1. Remove HTML\n",
        "    reviews_text = list(map(lambda x: BeautifulSoup(x, 'html.parser').get_text(), reviews))\n",
        "    #\n",
        "    # 2. Remove non-letters\n",
        "    reviews_text = list(map(lambda x: re.sub(\"[^a-zA-Z]\",\" \", x), reviews_text))\n",
        "    #\n",
        "    # 3. Convert words to lower case and split them\n",
        "    words = list(map(lambda x: x.lower().split(), reviews_text))\n",
        "    #\n",
        "    # 4. Optionally remove stop words (false by default)\n",
        "    if remove_stopwords:\n",
        "        set_of_stopwords = set(stopwords.words(\"english\"))\n",
        "        meaningful_words = list(map(lambda x: [w for w in x if not w in set_of_stopwords], words))\n",
        "    \n",
        "    # 5. Optionally stem the words\n",
        "    if stem:\n",
        "        porter_stemmer = PorterStemmer()\n",
        "        wordnet_lemmatizer = WordNetLemmatizer()\n",
        "        stemmed_words = list(map(lambda x: [porter_stemmer.stem(w) for w in x], meaningful_words))\n",
        "        stemmed_words = list(map(lambda x:[wordnet_lemmatizer.lemmatize(w) for w in x], stemmed_words))\n",
        "    \n",
        "        # 6. Join the words to a single string\n",
        "        clean_review = map(lambda x: ' '.join(x), stemmed_words)\n",
        "    else:\n",
        "        clean_review = list(map(lambda x: ' '.join(x), meaningful_words))\n",
        "    \n",
        "    return clean_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKBZIWdTyK5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a bag of words for the test set, and convert to a numpy array\n",
        "clean_test_reviews = clean_reviews(list(test['review'].values), remove_stopwords=True)\n",
        "test_data_features = vectorizer.transform(clean_test_reviews)\n",
        "test_data_features = test_data_features.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-DyFXTzfHS6",
        "colab_type": "text"
      },
      "source": [
        "###Build models with train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOCTWV14fD-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(train['review_cleaned'], train['sentiment'], test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_k1OHlNfouC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twn959ZLf68Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the sentence into a vector of number \n",
        "X_train_bag = count_vectorizer.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heHNaw7mgUxg",
        "colab_type": "text"
      },
      "source": [
        "###TfIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNLuVlxogQOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the sentences into vectors of numbers using tfidf method \n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsFFwTdyFKLZ",
        "colab_type": "text"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqON05mTAJlN",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjUT_bNr2SBk",
        "colab_type": "code",
        "outputId": "7f002205-2174-4670-a6f0-6702e4564859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
        "rfc.fit(X_train_tfidf, y_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "y_pred = rfc.predict(X_test_tfidf)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1907  332]\n",
            " [ 318 1943]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85      2239\n",
            "           1       0.85      0.86      0.86      2261\n",
            "\n",
            "    accuracy                           0.86      4500\n",
            "   macro avg       0.86      0.86      0.86      4500\n",
            "weighted avg       0.86      0.86      0.86      4500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04yjNh4QATec",
        "colab_type": "text"
      },
      "source": [
        "Bag of words performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0ptatC4SLb",
        "colab_type": "code",
        "outputId": "95dd11e5-2737-44b8-a176-033fdabc8120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
        "rfc.fit(X_train_bag, y_train)\n",
        "X_test_bow = count_vectorizer.transform(X_test)\n",
        "y_pred = rfc.predict(X_test_bow)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1926  313]\n",
            " [ 328 1933]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86      2239\n",
            "           1       0.86      0.85      0.86      2261\n",
            "\n",
            "    accuracy                           0.86      4500\n",
            "   macro avg       0.86      0.86      0.86      4500\n",
            "weighted avg       0.86      0.86      0.86      4500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngryLYPk5WrS",
        "colab_type": "text"
      },
      "source": [
        "###K-nearest neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_39MI_FEBN0S",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVQfFVM5Vk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "16a723e6-f606-44cc-ba5a-14456dc3c069"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2, weights='distance')\n",
        "knn.fit(X_train_tfidf, y_train)\n",
        "y_pred = knn.predict(X_test_tfidf)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1563  676]\n",
            " [ 380 1881]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.70      0.75      2239\n",
            "           1       0.74      0.83      0.78      2261\n",
            "\n",
            "    accuracy                           0.77      4500\n",
            "   macro avg       0.77      0.77      0.76      4500\n",
            "weighted avg       0.77      0.77      0.76      4500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGZ9FD4eBPii",
        "colab_type": "text"
      },
      "source": [
        "Bag of words performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU5DPHt85jN2",
        "colab_type": "code",
        "outputId": "ae951454-7e7b-47ec-856f-d64e15d1ecd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2, weights='distance')\n",
        "knn.fit(X_train_bag, y_train)\n",
        "y_pred = knn.predict(X_test_bow)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1437  802]\n",
            " [1010 1251]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.64      0.61      2239\n",
            "           1       0.61      0.55      0.58      2261\n",
            "\n",
            "    accuracy                           0.60      4500\n",
            "   macro avg       0.60      0.60      0.60      4500\n",
            "weighted avg       0.60      0.60      0.60      4500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44LfkyCNDmnT",
        "colab_type": "text"
      },
      "source": [
        "Base on the outcome accuracy, the random forest model is chosen to evaluate the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jvQgxYE2cS4",
        "colab_type": "text"
      },
      "source": [
        "###Time to test it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I39p-lZK7zZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the forest to the training set, using the bag of words as features and the sentiment labels as labels\n",
        "rfc.fit(train_data_features, train['sentiment'])\n",
        "\n",
        "# Use the random forest to make sentiment label predictions\n",
        "result = rfc.predict(test_data_features)\n",
        "output = pd.DataFrame(data={'id':test['id'],'sentiment':result})\n",
        "\n",
        "# # Use pandas to write the comma-separated output file\n",
        "output.to_csv(r'rfc_results.csv', index=False, quoting=3)\n",
        "files.download('rfc_results.csv')   \n",
        "print('Wrote results complete')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}